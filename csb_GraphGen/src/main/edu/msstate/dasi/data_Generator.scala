package edu.msstate.dasi

import org.apache.spark.SparkContext
import org.apache.spark.graphx.{Edge, VertexId}
import org.apache.spark.rdd.RDD

import scala.util.Random

/**
  * Created by justin on 12/5/2016.
  */

import scala.io.Source

class data_Generator extends Serializable {
  var edgeCnt: String = ""
  var originalBytesStr: String = ""
  var originalIPByteCntStr: String = ""
  var connectionStateStr: String = ""
  var connectionTypeStr: String = ""
  var durationStr: String = ""
  var originalPackCntStr: String = ""
  var respByteCntStr: String = ""
  var respIPByteCntStr: String = ""
  var respPackCntStr: String = ""


  //constructor
  {
    this.edgeCnt = readFile("Edge_distributions")
    this.originalBytesStr = readFile("Original_byte_count")
    this.originalIPByteCntStr = readFile("Original_IP_byte_count")
    this.connectionStateStr = readFile("Connection_state")
    this.connectionTypeStr = readFile("Connection_type")
    this.durationStr = readFile("Duration_of_connection")
    this.originalPackCntStr = readFile("Original_packet_count")
    this.respByteCntStr = readFile("Resp_byte_count")
    this.respIPByteCntStr = readFile("Resp_IP_byte_count")
    this.respPackCntStr = readFile("Resp_packet_count")
  }


  def readFile(fileName: String): String = {
    return Source.fromFile(fileName).mkString
  }


  def getEdgeCount(): Int = {
    return generateRandNumFromFileDist(this.edgeCnt)
  }

  def getOriginalByteCount(): Long = {
    return generateRandNumFromFileDist(this.originalBytesStr)
  }

  def getOriginalIPByteCount(byteCnt: Long, sc: SparkContext): Long = {
    return generateRandNumBasedBytes(this.originalIPByteCntStr, byteCnt, sc)
  }

  def getConnectState(byteCnt: Long, sc: SparkContext): String = {
    return generateRandStrBasedBytes(this.connectionStateStr, byteCnt, sc)
  }

  def getConnectType(byteCnt: Long, sc: SparkContext): String = {
    return generateRandStrBasedBytes(this.connectionTypeStr, byteCnt, sc)
  }

  def getDuration(byteCnt: Long, sc: SparkContext): Double = {
    return generateRandDoubleWithinRange(generateRandStrBasedBytes(this.durationStr, byteCnt, sc).split("\t")(0))
  }

  def getOriginalPackCnt(byteCnt: Long, sc: SparkContext): Long = {
    return generateRandNumBasedBytes(this.originalPackCntStr, byteCnt, sc)
  }

  def getRespByteCnt(byteCnt: Long, sc: SparkContext): Long = {
    return generateRandNumBasedBytes(this.respByteCntStr, byteCnt, sc)
  }

  def getRespIPByteCnt(byteCnt: Long, sc: SparkContext): Long = {
    return generateRandNumBasedBytes(this.respIPByteCntStr, byteCnt, sc)
  }

  def getRespPackCnt(byteCnt: Long, sc: SparkContext): Long = {
    return generateRandNumBasedBytes(this.respPackCntStr, byteCnt, sc)
  }

  def generateNodeData(): String = {
    val r = Random

    r.nextInt(255) + "." + r.nextInt(255) + "." + r.nextInt(255) + "." + r.nextInt(255) + ":" + r.nextInt(65536)
  }

  /** *
    * This function reads a distrobution that is not based on Original Bytes (independent of anything)
    * and picks a number based on the distribution.
    *
    * @param fileContents the contents of one of the files is generated by examining a conn.log file.
    * @return a random number based on a distrobution
    */
  def generateRandNumFromFileDist(fileContents: String): Int = {
    val r = new Random
    val numEdgesProb = r.nextFloat()
    var chance = 0.0
    var num = 0
    var strIter = fileContents.split("\n").toIterator
    while (strIter.hasNext && num == 0) {
      val line = strIter.next()
      val percentage = line.split("\\*")(1).split("\t")(1).toFloat
      chance = chance + percentage
      if (chance > numEdgesProb) {
        if (!line.split("\t")(0).contains("-")) {
          num = line.split("\t")(0).split("\\*")(1).toInt //split is a reg expression function so i escape the *
        }
        else {
          val firstTabLine = line.split("\t")(0)
          val begin: Int = firstTabLine.split("\\*")(1).split("-")(0).toInt
          val end: Int = firstTabLine.split("\\*")(1).split("-")(1).toInt
          num = r.nextInt(end - begin) + begin
        }
      }
    }
    num
  }

  /** *
    * This function returns a random number but with respect to the number of Original Bytes the connection had.
    * This is to prevent randomly generating bad data such as:
    * Original Bytes: 2GB
    * NumPackets: 2
    *
    * @param fileContents the contents of one of the files is generated by examining a conn.log file.
    * @param byteNum      The number of bytes this connection had.
    * @param sc           A spark context
    * @return
    */
  def generateRandNumBasedBytes(fileContents: String, byteNum: Long, sc: SparkContext): Long = {
    val r = new Random
    val numEdgesProb = r.nextFloat()
    var chance = 0.0
    var num = 0

    val splitFileContents = sc.parallelize(fileContents.split("\n"))
    var text = splitFileContents.filter(record => record.split("\\*")(0).split("-")(0).toLong <= byteNum && record.split("\\*")(0).split("-")(1).toLong >= byteNum)

    //    var allStr = ""
    //
    //    for (aStr <- text.collect())
    //    {
    //      allStr = allStr + aStr + "\n"
    //    }

    //    var temp = new FileWriter("temp")
    //
    //    temp.write(allStr)
    //    temp.close()

    var line: String = generateRandStrFromFileDist(text.toLocalIterator)

    val range: String = line.split("\t").head.split("\\*")(1)

    val begin: Int = range.split("-").head.toInt
    val end: Int = range.split("-")(1).toInt

    return r.nextInt(end - begin) + begin
  }

  def generateRandDoubleWithinRange(range: String): Double = {
    val begin = range.split("-")(0).toInt
    val end = range.split("-")(1).toInt

    val r = Random
    val decimal = r.nextDouble()
    val digit = r.nextInt(end - begin) + begin
    return digit + decimal
  }

  def generateRandStrBasedBytes(fileContents: String, byteNum: Long, sc: SparkContext): String = {
    val r = new Random
    val numEdgesProb = r.nextFloat()
    var chance = 0.0
    var num = 0
    var rdd = sc.parallelize(fileContents.split("\n"))
    //    fileIter.next() //we do the next here since the heading is always just text describeing the file


    //    var file = sc.textFile(filename)
    var text = rdd.filter(record => record.split("\\*")(0).split("-")(0).toLong <= byteNum && record.split("\\*")(0).split("-")(1).toLong >= byteNum)

    //
    //    var allStr = ""
    //
    //    for (aStr <- text.collect())
    //    {
    //      allStr = allStr + aStr + "\n"
    //    }
    //
    //
    //    var temp = new FileWriter("temp")
    //
    //    temp.write(allStr)
    //    temp.close()

    val line = generateRandStrFromFileDist(text.toLocalIterator)

    return line.split(" ").head.split("\\*")(1)
  }

  /** *
    * Given a set of of lines pick one at random
    * This function is very similar to generateRandNumFromFileDist
    * but instead of getting a number this function returns the line that it picks
    *
    * @param fileIter : The contents of the file in a string iter
    * @return a weighted random line
    */
  def generateRandStrFromFileDist(fileIter: Iterator[String]): String = {
    val r = new Random
    val numEdgesProb = r.nextFloat()
    var chance = 0.0
    var num = 0


    while (fileIter.hasNext && num == 0) {
      val line = fileIter.next()
      val percentage = line.split("\t")(1).toFloat
      chance = chance + percentage
      if (chance > numEdgesProb) {
        return line
      }
    }
    return null
  }

  def generateNodeProperties(sc: SparkContext, vRDD: RDD[(VertexId, nodeData)]): RDD[(VertexId, nodeData)] = {

    val gen_vRDD = vRDD.map(record => (record._1, generateNode()))

    gen_vRDD
  }

  private def generateNode(): nodeData = {
    nodeData(generateNodeData())
  }

  def generateEdgeProperties(sc: SparkContext, eRDD: RDD[Edge[edgeData]]): RDD[Edge[edgeData]] = {
    val gen_eRDD = eRDD.map(record => Edge(record.srcId, record.dstId, generateEdge()))

    gen_eRDD
  }

  private def generateEdge(): edgeData = {
    val sc: SparkContext = new SparkContext()
    val ORIGBYTES = getOriginalByteCount()
    val ORIGIPBYTE = getOriginalIPByteCount(ORIGBYTES, sc)
    val CONNECTSTATE = getConnectState(ORIGBYTES, sc)
    val CONNECTTYPE = getConnectType(ORIGBYTES, sc)
    val DURATION = getDuration(ORIGBYTES, sc)
    val ORIGPACKCNT = getOriginalPackCnt(ORIGBYTES, sc)
    val RESPBYTECNT = getRespByteCnt(ORIGBYTES, sc)
    val RESPIPBYTECNT = getRespIPByteCnt(ORIGBYTES, sc)
    val RESPPACKCNT = getRespPackCnt(ORIGBYTES, sc)
    edgeData("", CONNECTTYPE, DURATION, ORIGBYTES, RESPBYTECNT, CONNECTSTATE, ORIGPACKCNT, ORIGIPBYTE, RESPPACKCNT, RESPBYTECNT, "")
    //val tempEdgeProp: edgeData = edgeData()
  }

}

