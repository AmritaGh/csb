package edu.msstate.dasi.csb

import edu.msstate.dasi.csb.cli.OptionParser
import edu.msstate.dasi.csb.config.{ComponentFactory, Config}
import edu.msstate.dasi.csb.data.distributions.DataDistributions
import edu.msstate.dasi.csb.model.{EdgeData, VertexData}
import edu.msstate.dasi.csb.data.seed.DataParser
import edu.msstate.dasi.csb.persistence.FileSerializer
import edu.msstate.dasi.csb.util.Util
import edu.msstate.dasi.csb.veracity.Veracity
import org.apache.log4j.{Level, Logger}
import org.apache.spark.graphx.Graph

import scala.util.Random

/**
 * User interface object. Handles option selection as well as command-line parameters
 */
object Benchmark {

  val versionString = "0.1.5-SNAPSHOT"

  /**
    * Insertion point for the program, controls flow of program between the different options.
    * @param args Array of command-line arguments to parse.
    */
  def main(args: Array[String]): Unit = {

    Logger.getLogger("org").setLevel(Level.ERROR)
    Logger.getLogger("akka").setLevel(Level.ERROR)

    val parser = new OptionParser("csb", versionString, Config())

    parser.parse(args) match {
      case Some(config) =>
        if ( config.debug ) {
          Logger.getLogger("org").setLevel(Level.DEBUG)
          Logger.getLogger("akka").setLevel(Level.DEBUG)
        }

        val factory = new ComponentFactory(config)

        config.mode match {
          case "seed" => run_seed(config, factory)
          case "synth" => run_synth(config, factory)
          case "veracity" => run_veracity(config, factory)
          case "workload" => run_workload(config, factory)
        }
      case None => sys.exit(1)
    }
  }

  /**
   * Method to generate a seed graph given a Bro connection log file
   *
   * @param config  Group of configuration variables, adjusted by the command-line inputs.
   * @param factory Spark ComponentFactory object for the application.
   *
   * @return
   */
  private def run_seed(config: Config, factory: ComponentFactory): Boolean = {
    val seed = Util.time( "Log to graph", {
      val seed = DataParser.logToGraph(config.connLog, config.partitions)
      println("Vertices #: " + seed.numVertices + ", Edges #: " + seed.numEdges)
      seed
    } )

    factory.getSaver match {
      case Some(saver) =>
        Util.time("Save seed graph", saver.saveGraph(seed, config.seedGraphPrefix, overwrite = true))
      case None =>
    }

    factory.getTextSaver match {
      case Some(textSaver) =>
        Util.time( "Save seed graph as text", textSaver.saveAsText(seed, config.seedGraphPrefix, overwrite = true) )
      case None =>
    }

    val distributions = Util.time("Gen seed distributions", DataDistributions(seed, config.bucketSize))

    Util.time("Save seed distributions", FileSerializer.save(distributions, config.seedDistributions))

    true
  }

  /**
   * Runs veracity metrics test(s) on a given seed graph and synthetically generated graph.
   *
   * @param metrics List of metrics to run on the graphs.
   * @param seed    Seed graph that was used to generate the synthetic graph. Considered absolute truth when measuring difference.
   * @param synth   Synthetic graph generated by [[run_synth()]]
   */
  private def run_metrics(metrics: Array[Veracity], seed: Graph[VertexData, EdgeData], synth: Graph[VertexData, EdgeData]): Unit = {
    for (metric <- metrics) {
      val veracity = Util.time(s"${metric.name} veracity", metric(seed, synth))
      println(s"${metric.name} veracity: $veracity")
    }
  }

  /**
   * Generated a synthetic graph using the specified generator as well as any relevant seed information. Also saves the
   * generated graph using the preferred backend.
   *
   * @param config  Group of configuration variables, adjusted by the command-line inputs.
   * @param factory Spark ComponentFactory object for the application.
   *
   * @return
   */
  private def run_synth(config: Config, factory: ComponentFactory): Boolean = {

    val seed = Util.time( "Load seed graph", {
      val seed = factory.getLoader.loadGraph(config.seedGraphPrefix, config.partitions)
      println("Vertices #: " + seed.numVertices + ", Edges #: " + seed.numEdges)
      seed
    } )

    val seedDistributions = Util.time("Load seed distributions",
      FileSerializer.load[DataDistributions](config.seedDistributions))

    val synth = factory.getSynthesizer.synthesize(seed, seedDistributions, !config.skipProperties)

    factory.getSaver match {
      case Some(saver) =>
        Util.time( "Save synth graph", saver.saveGraph(synth, config.synthGraphPrefix, overwrite = true))
      case None =>
    }

    factory.getTextSaver match {
      case Some(textSaver) =>
        Util.time( "Save synth graph as text", textSaver.saveAsText(synth, config.synthGraphPrefix, overwrite = true) )
      case None =>
    }

    run_metrics(factory.getMetrics, seed, synth)

    true
  }

  /**
   * Loads both seed graph and synthetic graph into memory and begins running the requested metrics on both.
   *
   * @param config  Group of configuration variables, adjusted by the command-line inputs.
   * @param factory Spark ComponentFactory object for the application.
   *
   * @return
   */
  private def run_veracity(config: Config, factory: ComponentFactory): Boolean = {
    val loader = factory.getLoader

    val seed = Util.time( "Load seed graph", loader.loadGraph(config.seedGraphPrefix, config.partitions) )

    val synth = Util.time( "Load synth graph", loader.loadGraph(config.synthGraphPrefix, config.partitions) )

    run_metrics(factory.getMetrics, seed, synth)

    true
  }

  /**
   * Runs a set of workloads on a specified graph and outputs the execution time.
   *
   * @param config  Group of configuration variables, adjusted by the command-line inputs.
   * @param factory Spark ComponentFactory object for the application.
   *
   * @return
   */
  private def run_workload(config: Config, factory: ComponentFactory): Boolean = {
    val loader = factory.getLoader

    val graph = Util.time( "Load graph", loader.loadGraph(config.graphPrefix, config.partitions) )

    for (workload <- factory.getWorkloads) {
      Util.time(s"${workload.name} workload", workload.run(graph))
    }

    true
  }
}
